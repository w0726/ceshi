{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "useDrive.ipynb",
      "provenance": [],
      "mount_file_id": "1YTkdN39h07FhCcrKqst6y9igmnVt-42k",
      "authorship_tag": "ABX9TyO/dQK19se56+U3u3rNjvDx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/w0726/ceshi/blob/master/0814.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdcnT0zKe6kA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "6ecee842-4fe5-4b18-f73a-0dbcb612cced"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUcR5RIRhwL_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "8f1bf8a2-ad9a-4035-d737-484459b61787"
      },
      "source": [
        "!ls -l 'drive/My Drive/mycode/dataset'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 2417810\n",
            "drwx------ 2 root root       4096 Aug  6 12:03 10classes\n",
            "-rw------- 1 root root 2475828275 Aug  5 15:23 10classes.zip\n",
            "drwx------ 2 root root       4096 Aug 14 02:36 2classes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a15jPAH1ipxA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !unzip 'drive/My Drive/mycode/dataset/10classes.zip' -d 'drive/My Drive/mycode/dataset'\n",
        "# !ls -l 'drive/My Drive/mycode/dataset/10classes'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUmvP7-h96Vq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "d01a51d3-0005-490e-af01-c37a599b93db"
      },
      "source": [
        "import os\n",
        "print(len(os.listdir('drive/My Drive/mycode/dataset/2classes')))\n",
        "!pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "259\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MsNvDxURAbzg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import tqdm\n",
        "import time\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "import torch.utils.data as data\n",
        "import torchvision\n",
        "from torch.autograd import Variable\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pickle\n",
        "\n",
        "\n",
        "# ------------------- label conversion tools ------------------ #\n",
        "\n",
        "\n",
        "def labels2cat(label_encoder, list):\n",
        "    return label_encoder.transform(list)\n",
        "\n",
        "\n",
        "def labels2onehot(onehotEncoder, label_encoder, list):\n",
        "    return onehotEncoder.transform(label_encoder.transform(list).reshape(-1, 1)).toarray()\n",
        "\n",
        "\n",
        "def onehot2labels(label_encoder, y_onehot):\n",
        "    return label_encoder.inverse_transform(np.where(y_onehot == 1)[1]).tolist()\n",
        "\n",
        "\n",
        "def cat2labels(label_encoder, y_cat):\n",
        "    return label_encoder.inverse_transform(y_cat).tolist()\n",
        "\n",
        "\n",
        "def cat2onehot(action_names: list):\n",
        "    # convert labels -> category\n",
        "    le = LabelEncoder()\n",
        "    le.fit(action_names)\n",
        "\n",
        "    # # show how many classes there are\n",
        "    # list(le.classes_)\n",
        "\n",
        "    # convert category -> 1-hot\n",
        "    action_category = le.transform(action_names).reshape(-1, 1)\n",
        "    enc = OneHotEncoder()\n",
        "    enc.fit(action_category)\n",
        "\n",
        "\n",
        "def getnames(data_path, action_name_path):\n",
        "    # load UCF101 actions names\n",
        "    with open(action_name_path, 'rb') as f:\n",
        "        action_names = pickle.load(f)   # load UCF101 actions names\n",
        "\n",
        "    # convert labels -> category\n",
        "    le = LabelEncoder()\n",
        "    le.fit(action_names)\n",
        "\n",
        "    # # show how many classes there are\n",
        "    # list(le.classes_)\n",
        "\n",
        "    # convert category -> 1-hot\n",
        "    action_category = le.transform(action_names).reshape(-1, 1)     # type: numpy.ndarray\n",
        "    enc = OneHotEncoder()\n",
        "    enc.fit(action_category)\n",
        "\n",
        "    # # example\n",
        "    # y = ['HorseRace', 'YoYo', 'WalkingWithDog']\n",
        "    # y_onehot = labels2onehot(enc, le, y)\n",
        "    # y2 = onehot2labels(le, y_onehot)\n",
        "\n",
        "    actions = []\n",
        "    fnames = os.listdir(data_path)\n",
        "\n",
        "    all_names = []\n",
        "    for f in fnames:\n",
        "        loc1 = f.find('v_')\n",
        "        loc2 = f.find('_g')\n",
        "        actions.append(f[(loc1 + 2): loc2])\n",
        "\n",
        "        all_names.append(f)\n",
        "\n",
        "    # list all data files\n",
        "    all_folders_list = all_names              # all video file names\n",
        "    all_labels_list = labels2cat(le, actions)    # all video labels, type: int\n",
        "\n",
        "    return all_folders_list, all_labels_list\n",
        "\n",
        "\n",
        "# ------------------------ 3D CNN module ---------------------- #\n",
        "\n",
        "\n",
        "def conv3D_output_size(img_size, padding, kernel_size, stride):\n",
        "    # compute output shape of conv3D\n",
        "    outshape = (np.floor((img_size[0] + 2 * padding[0] - (kernel_size[0] - 1) - 1) / stride[0] + 1).astype(int),\n",
        "                np.floor((img_size[1] + 2 * padding[1] - (kernel_size[1] - 1) - 1) / stride[1] + 1).astype(int),\n",
        "                np.floor((img_size[2] + 2 * padding[2] - (kernel_size[2] - 1) - 1) / stride[2] + 1).astype(int))\n",
        "    return outshape\n",
        "\n",
        "\n",
        "class CNN3D(nn.Module):\n",
        "    def __init__(self, t_dim=120, img_x=90, img_y=120, drop_p=0.2, fc_hidden1=256, fc_hidden2=128, num_classes=50):\n",
        "        super(CNN3D, self).__init__()\n",
        "\n",
        "        # set video dimension\n",
        "        self.t_dim = t_dim\n",
        "        self.img_x = img_x\n",
        "        self.img_y = img_y\n",
        "        # fully connected layer hidden nodes\n",
        "        self.fc_hidden1, self.fc_hidden2 = fc_hidden1, fc_hidden2\n",
        "        self.drop_p = drop_p\n",
        "        self.num_classes = num_classes\n",
        "        self.ch1, self.ch2 = 32, 48\n",
        "        self.k1, self.k2 = (5, 5, 5), (3, 3, 3)  # 3d kernel size\n",
        "        self.s1, self.s2 = (2, 2, 2), (2, 2, 2)  # 3d strides\n",
        "        self.pd1, self.pd2 = (0, 0, 0), (0, 0, 0)  # 3d padding\n",
        "\n",
        "        # compute conv1 & conv2 output shape\n",
        "        self.conv1_outshape = conv3D_output_size((self.t_dim, self.img_x, self.img_y), self.pd1, self.k1, self.s1)\n",
        "        self.conv2_outshape = conv3D_output_size(self.conv1_outshape, self.pd2, self.k2, self.s2)\n",
        "\n",
        "        self.conv1 = nn.Conv3d(in_channels=1, out_channels=self.ch1, kernel_size=self.k1, stride=self.s1,\n",
        "                               padding=self.pd1)\n",
        "        self.bn1 = nn.BatchNorm3d(self.ch1)\n",
        "        self.conv2 = nn.Conv3d(in_channels=self.ch1, out_channels=self.ch2, kernel_size=self.k2, stride=self.s2,\n",
        "                               padding=self.pd2)\n",
        "        self.bn2 = nn.BatchNorm3d(self.ch2)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.drop = nn.Dropout3d(self.drop_p)\n",
        "        self.pool = nn.MaxPool3d(2)\n",
        "        self.fc1 = nn.Linear(self.ch2 * self.conv2_outshape[0] * self.conv2_outshape[1] * self.conv2_outshape[2],\n",
        "                             self.fc_hidden1)  # fully connected hidden layer\n",
        "        self.fc2 = nn.Linear(self.fc_hidden1, self.fc_hidden2)\n",
        "        self.fc3 = nn.Linear(self.fc_hidden2, self.num_classes)  # fully connected layer, output = multi-classes\n",
        "\n",
        "    def forward(self, x_3d):\n",
        "        # Conv 1\n",
        "        x = self.conv1(x_3d)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.drop(x)\n",
        "        # Conv 2\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.drop(x)\n",
        "        # FC 1 and 2\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.dropout(x, p=self.drop_p, training=self.training)\n",
        "        x = self.fc3(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "# ---------------------- Dataloaders ---------------------- #\n",
        "# for 3DCNN\n",
        "class Dataset_3DCNN(data.Dataset):\n",
        "    \"\"\"Characterizes a dataset for PyTorch\"\"\"\n",
        "\n",
        "    '''\n",
        "        data_path: the root dir of vedios\n",
        "        folders: all vedio file names in the dataset, a folder contains a vedio devided by frame\n",
        "        labels: all labels of the vedio in the dataset\n",
        "        frames: numpy.ndarray, contains the indexes of frames to be trained in each vedio\n",
        "        transform: torchvision.transforms\n",
        "    '''\n",
        "\n",
        "    def __init__(self, data_path, folders, labels, frames, transform=None):\n",
        "        \"Initialization\"\n",
        "        self.data_path = data_path\n",
        "        self.labels = labels\n",
        "        self.folders = folders\n",
        "        self.transform = transform\n",
        "        self.frames = frames\n",
        "\n",
        "    def __len__(self):\n",
        "        \"Denotes the total number of samples\"\n",
        "        return len(self.folders)\n",
        "\n",
        "    def read_images(self, data_path, folder, use_transform):\n",
        "        \"\"\"\n",
        "            path: the root dir of selected_folder, the same as self.data_path\n",
        "        \"\"\"\n",
        "        X = []\n",
        "        for i in self.frames:\n",
        "            image = Image.open(os.path.join(data_path, folder, 'frame{:06d}.jpg'.format(i))).convert('L')\n",
        "\n",
        "            if use_transform is not None:\n",
        "                image = use_transform(image)\n",
        "\n",
        "            X.append(image.squeeze_(0))  # 灰度图像， 1通道，dim=0的元素个数为1时，删去该维度\n",
        "        X = torch.stack(X, dim=0)   # 增加新维度，在0维上堆叠\n",
        "\n",
        "        return X\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"Generates one sample of data\"\n",
        "        # Select sample\n",
        "        folder = self.folders[idx]\n",
        "\n",
        "        # Load data\n",
        "        data = self.read_images(self.data_path, folder, self.transform).unsqueeze_(0)  # (input) spatial images\n",
        "        targets = torch.LongTensor([self.labels[idx]])                             # (target) LongTensor are for int64 instead of FloatTensor\n",
        "\n",
        "        # print(data.shape)\n",
        "        return data, targets\n",
        "\n",
        "\n",
        "# ---------------------- Train for 3DCNN ---------------------- #\n",
        "def train(log_interval, model, device, train_loader, optimizer, epoch):\n",
        "    start = time.time()\n",
        "    print(f'{time.asctime(time.localtime(start))}')\n",
        "    # set model as training mode\n",
        "    model.train()\n",
        "\n",
        "    losses = []\n",
        "    scores = []\n",
        "    N_count = 0   # counting total trained sample in one epoch\n",
        "    for batch_idx, (X, y) in enumerate(train_loader):\n",
        "        # distribute data to device\n",
        "        X, y = X.to(device), y.to(device).view(-1, )\n",
        "        # print(X.size(), y)\n",
        "\n",
        "        N_count += X.size(0)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model(X)  # output size = (batch, number of classes)\n",
        "\n",
        "        loss = F.cross_entropy(output, y)\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        # to compute accuracy\n",
        "        y_pred = torch.max(output, 1)[1]  # y_pred != output\n",
        "        # print(f'y_pred:\\n{y_pred}\\ny:\\n{y}')\n",
        "        step_score = accuracy_score(y.cpu().data.squeeze().numpy(), y_pred.cpu().data.squeeze().numpy())\n",
        "        scores.append(step_score)         # computed on CPU\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # show information\n",
        "        if (batch_idx + 1) % log_interval == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}, Accu: {:.2f}%'.format(\n",
        "                epoch + 1, N_count, len(train_loader.dataset), 100. * (batch_idx + 1) / len(train_loader), loss.item(), 100 * step_score))\n",
        "    print(f'[{time.time()-start}s]\\tTrain Epoch {epoch+1} is done.')\n",
        "    return losses, scores\n",
        "\n",
        "\n",
        "# ---------------------- Validation for 3DCNN ---------------------- #\n",
        "def validation(model, device, optimizer, test_loader, epoch, save_model_path, last_val_loss, last_val_score):\n",
        "    print(f'{time.ctime()}')\n",
        "    # set model as testing mode\n",
        "    model.eval()\n",
        "\n",
        "    test_loss = 0\n",
        "    all_y = []\n",
        "    all_y_pred = []\n",
        "    with torch.no_grad():\n",
        "        for X, y in test_loader:\n",
        "            # distribute data to device\n",
        "            X, y = X.to(device), y.to(device).view(-1, )\n",
        "\n",
        "            output = model(X)\n",
        "\n",
        "            loss = F.cross_entropy(output, y, reduction='sum')\n",
        "            test_loss += loss.item()                 # sum up batch loss\n",
        "            y_pred = output.max(1, keepdim=True)[1]  # (y_pred != output) get the index of the max log-probability\n",
        "\n",
        "            # collect all y and y_pred in all batches\n",
        "            all_y.extend(y)\n",
        "            all_y_pred.extend(y_pred)\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    # to compute accuracy\n",
        "    all_y = torch.stack(all_y, dim=0)\n",
        "    all_y_pred = torch.stack(all_y_pred, dim=0)\n",
        "    test_score = accuracy_score(all_y.cpu().data.squeeze().numpy(), all_y_pred.cpu().data.squeeze().numpy())\n",
        "\n",
        "    # show information\n",
        "    print('\\nTest set ({:d} samples): Average loss: {:.4f}, Accuracy: {:.2f}%\\n'.format(len(all_y), test_loss, 100 * test_score))\n",
        "\n",
        "    # save Pytorch models of best record\n",
        "    if test_loss < last_val_loss or test_score > last_val_score:\n",
        "      torch.save(model.state_dict(), os.path.join(save_model_path, '3dcnn_epoch{}.pth'.format(epoch + 1)))  # save spatial_encoder\n",
        "      torch.save(optimizer.state_dict(), os.path.join(save_model_path, '3dcnn_optimizer_epoch{}.pth'.format(epoch + 1)))      # save optimizer\n",
        "      print(f\"Epoch {epoch+1} model saved!\\n\")\n",
        "\n",
        "    return test_loss, test_score\n",
        "\n",
        "\n",
        "# -------------------- (reload) model prediction ---------------------- #\n",
        "def Conv3d_final_prediction(model, device, loader):\n",
        "    model.eval()\n",
        "\n",
        "    all_y_pred = []\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (X, y) in enumerate(tqdm(loader)):\n",
        "            # distribute data to device\n",
        "            X = X.to(device)\n",
        "            output = model(X)\n",
        "            y_pred = output.max(1, keepdim=True)[1]  # location of max log-probability as prediction\n",
        "            all_y_pred.extend(y_pred.cpu().data.squeeze().numpy().tolist())\n",
        "\n",
        "    return all_y_pred\n",
        "\n",
        "\n",
        "# -------------------- DRAW PLOT ---------------------- #\n",
        "\n",
        "def draw(epoch_size: int, epoch_train_losses: np.ndarray, epoch_train_scores: np.ndarray, epoch_test_losses: np.ndarray, epoch_test_scores: np.ndarray):\n",
        "    # plot\n",
        "    fig = plt.figure(figsize=(10, 4))\n",
        "    plt.subplot(121)\n",
        "    plt.plot(np.arange(1, epoch_size + 1), epoch_train_losses[:, -1])  # train loss (on epoch end)\n",
        "    plt.plot(np.arange(1, epoch_size + 1), epoch_test_losses)  # test loss (on epoch end)\n",
        "    plt.title(\"model loss\")\n",
        "    plt.xlabel('epochs')\n",
        "    plt.ylabel('loss')\n",
        "    plt.legend(['train', 'test'], loc=\"upper left\")\n",
        "    # 2nd figure\n",
        "    plt.subplot(122)\n",
        "    plt.plot(np.arange(1, epoch_size + 1), epoch_train_scores[:, -1])  # train accuracy (on epoch end)\n",
        "    plt.plot(np.arange(1, epoch_size + 1), epoch_test_scores)  # test accuracy (on epoch end)\n",
        "    # plt.plot(histories.losses_val)\n",
        "    plt.title(\"training scores\")\n",
        "    plt.xlabel('epochs')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.legend(['train', 'test'], loc=\"upper left\")\n",
        "    title = \"./fig_UCF101_3DCNN.png\"\n",
        "    # plt.savefig(title, dpi=600)\n",
        "    # plt.close(fig)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def main():\n",
        "\n",
        "    # set path\n",
        "    data_path = \"drive/My Drive/mycode/dataset/2classes\"    # define UCF-101 spatial data path\n",
        "    action_name_path = \"drive/My Drive/mycode/classes.pkl\"  # load preprocessed action names\n",
        "    save_model_path = \"drive/My Drive/mycode/Conv3D_ckpt/\"  # save Pytorch models\n",
        "\n",
        "    # Detect devices\n",
        "    use_cuda = torch.cuda.is_available()                   # check if GPU exists\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")   # use CPU or GPU\n",
        "\n",
        "    # load UCF101 actions names\n",
        "    all_folders_list, all_labels_list = getnames(data_path, action_name_path)\n",
        "\n",
        "    # train, test split\n",
        "    train_list, test_list, train_label, test_label = train_test_split(all_folders_list, all_labels_list, test_size=0.25, random_state=42)\n",
        "\n",
        "    # image transformation\n",
        "    img_x, img_y = 256, 342  # resize video 2d frame size\n",
        "    transform = transforms.Compose([transforms.Resize([img_x, img_y]),\n",
        "                                    transforms.ToTensor(),\n",
        "                                    transforms.Normalize(mean=[0.5], std=[0.5])])\n",
        "\n",
        "    # Get datasat and dataloader\n",
        "    begin_frame, end_frame, skip_frame = 1, 10, 1   # Select which frame to begin & end in videos\n",
        "    selected_frames = np.arange(begin_frame, end_frame, skip_frame).tolist()\n",
        "    train_set = Dataset_3DCNN(data_path, train_list, train_label, selected_frames, transform=transform)\n",
        "    valid_set = Dataset_3DCNN(data_path, test_list, test_label, selected_frames, transform=transform)\n",
        "\n",
        "    batch_size = 5\n",
        "    params = {'batch_size': batch_size, 'shuffle': True, 'num_workers': 4, 'pin_memory': True} if use_cuda else {'batch_size': batch_size, 'shuffle': True}\n",
        "    train_loader = data.DataLoader(train_set, **params)\n",
        "    valid_loader = data.DataLoader(valid_set, **params)\n",
        "\n",
        "    # create model\n",
        "    # 3D CNN parameters\n",
        "    num_classes = 2            # number of target category\n",
        "    fc_hidden1, fc_hidden2 = 256, 256\n",
        "    dropout = 0.0        # dropout probability\n",
        "\n",
        "    cnn3d = CNN3D(t_dim=len(selected_frames),   # 时间维度\n",
        "                  img_x=img_x,\n",
        "                  img_y=img_y,\n",
        "                  drop_p=dropout,\n",
        "                  fc_hidden1=fc_hidden1,\n",
        "                  fc_hidden2=fc_hidden2,\n",
        "                  num_classes=num_classes).to(device)\n",
        "\n",
        "    # Parallelize model to multiple GPUs\n",
        "    if torch.cuda.device_count() > 1:\n",
        "        print(\"Using\", torch.cuda.device_count(), \"GPUs!\")\n",
        "        cnn3d = nn.DataParallel(cnn3d)\n",
        "\n",
        "    # 训练及验证\n",
        "    # training parameters\n",
        "    epoch_size = 5\n",
        "    learning_rate = 1e-4\n",
        "    log_interval = 2\n",
        "\n",
        "    optimizer = torch.optim.Adam(cnn3d.parameters(), lr=learning_rate)   # optimize all cnn parameters\n",
        "\n",
        "    # record training process\n",
        "    epoch_train_losses = []\n",
        "    epoch_train_scores = []\n",
        "    epoch_test_losses = []\n",
        "    epoch_test_scores = []\n",
        "\n",
        "    print(f'Epoch size: {epoch_size}\\tBatch size: {batch_size}\\tLearning rate: {learning_rate}')\n",
        "    last_val_loss, last_val_score = 0, 0\n",
        "    for epoch in range(epoch_size):\n",
        "        # train, test model\n",
        "        train_losses, train_scores = train(log_interval, cnn3d, device, train_loader, optimizer, epoch)\n",
        "        epoch_test_loss, epoch_test_score = validation(cnn3d, device, optimizer, valid_loader, epoch, save_model_path, last_val_loss, last_val_score)\n",
        "        last_val_loss = epoch_test_loss\n",
        "        last_val_score = epoch_test_score\n",
        "\n",
        "        # save results\n",
        "        epoch_train_losses.append(train_losses)\n",
        "        epoch_train_scores.append(train_scores)\n",
        "        epoch_test_losses.append(epoch_test_loss)\n",
        "        epoch_test_scores.append(epoch_test_score)\n",
        "\n",
        "        # save all train test results\n",
        "        A = np.array(epoch_train_losses)\n",
        "        B = np.array(epoch_train_scores)\n",
        "        C = np.array(epoch_test_losses)\n",
        "        D = np.array(epoch_test_scores)\n",
        "        np.save('./3DCNN_epoch_training_losses.npy', A)\n",
        "        np.save('./3DCNN_epoch_training_scores.npy', B)\n",
        "        np.save('./3DCNN_epoch_test_loss.npy', C)\n",
        "        np.save('./3DCNN_epoch_test_score.npy', D)\n",
        "\n",
        "    # 作图\n",
        "    return epoch_size, A, B, C, D\n",
        "    # draw(epoch_size, A, B, C, D)\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1Tv4ISI31ER",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2426
        },
        "outputId": "749803b1-e55f-44d9-a723-e0648ebe1932"
      },
      "source": [
        "epoch_size, A, B, C, D = main()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch size: 5\tBatch size: 5\tLearning rate: 0.0001\n",
            "Fri Aug 14 05:33:40 2020\n",
            "Train Epoch: 1 [10/194 (5%)]\tLoss: 1.994395, Accu: 40.00%\n",
            "Train Epoch: 1 [20/194 (10%)]\tLoss: 0.866395, Accu: 40.00%\n",
            "Train Epoch: 1 [30/194 (15%)]\tLoss: 2.266103, Accu: 40.00%\n",
            "Train Epoch: 1 [40/194 (21%)]\tLoss: 0.582366, Accu: 80.00%\n",
            "Train Epoch: 1 [50/194 (26%)]\tLoss: 0.593355, Accu: 80.00%\n",
            "Train Epoch: 1 [60/194 (31%)]\tLoss: 2.410541, Accu: 0.00%\n",
            "Train Epoch: 1 [70/194 (36%)]\tLoss: 0.480117, Accu: 80.00%\n",
            "Train Epoch: 1 [80/194 (41%)]\tLoss: 0.781112, Accu: 60.00%\n",
            "Train Epoch: 1 [90/194 (46%)]\tLoss: 0.763960, Accu: 80.00%\n",
            "Train Epoch: 1 [100/194 (51%)]\tLoss: 0.388168, Accu: 80.00%\n",
            "Train Epoch: 1 [110/194 (56%)]\tLoss: 0.618663, Accu: 80.00%\n",
            "Train Epoch: 1 [120/194 (62%)]\tLoss: 0.240954, Accu: 80.00%\n",
            "Train Epoch: 1 [130/194 (67%)]\tLoss: 0.398494, Accu: 80.00%\n",
            "Train Epoch: 1 [140/194 (72%)]\tLoss: 0.259341, Accu: 100.00%\n",
            "Train Epoch: 1 [150/194 (77%)]\tLoss: 0.669110, Accu: 60.00%\n",
            "Train Epoch: 1 [160/194 (82%)]\tLoss: 0.999445, Accu: 60.00%\n",
            "Train Epoch: 1 [170/194 (87%)]\tLoss: 0.507366, Accu: 80.00%\n",
            "Train Epoch: 1 [180/194 (92%)]\tLoss: 0.506002, Accu: 60.00%\n",
            "Train Epoch: 1 [190/194 (97%)]\tLoss: 0.538891, Accu: 60.00%\n",
            "[5.111264705657959s]\tTrain Epoch 1 is done.\n",
            "Fri Aug 14 05:33:45 2020\n",
            "\n",
            "Test set (65 samples): Average loss: 0.4007, Accuracy: 92.31%\n",
            "\n",
            "Epoch 1 model saved!\n",
            "\n",
            "Fri Aug 14 05:33:50 2020\n",
            "Train Epoch: 2 [10/194 (5%)]\tLoss: 0.076592, Accu: 100.00%\n",
            "Train Epoch: 2 [20/194 (10%)]\tLoss: 0.348637, Accu: 80.00%\n",
            "Train Epoch: 2 [30/194 (15%)]\tLoss: 0.020612, Accu: 100.00%\n",
            "Train Epoch: 2 [40/194 (21%)]\tLoss: 0.408444, Accu: 80.00%\n",
            "Train Epoch: 2 [50/194 (26%)]\tLoss: 0.355284, Accu: 80.00%\n",
            "Train Epoch: 2 [60/194 (31%)]\tLoss: 0.129766, Accu: 100.00%\n",
            "Train Epoch: 2 [70/194 (36%)]\tLoss: 0.048974, Accu: 100.00%\n",
            "Train Epoch: 2 [80/194 (41%)]\tLoss: 0.307901, Accu: 80.00%\n",
            "Train Epoch: 2 [90/194 (46%)]\tLoss: 0.429818, Accu: 80.00%\n",
            "Train Epoch: 2 [100/194 (51%)]\tLoss: 0.197488, Accu: 80.00%\n",
            "Train Epoch: 2 [110/194 (56%)]\tLoss: 0.089336, Accu: 100.00%\n",
            "Train Epoch: 2 [120/194 (62%)]\tLoss: 0.015976, Accu: 100.00%\n",
            "Train Epoch: 2 [130/194 (67%)]\tLoss: 0.117028, Accu: 100.00%\n",
            "Train Epoch: 2 [140/194 (72%)]\tLoss: 0.066549, Accu: 100.00%\n",
            "Train Epoch: 2 [150/194 (77%)]\tLoss: 0.045477, Accu: 100.00%\n",
            "Train Epoch: 2 [160/194 (82%)]\tLoss: 0.057517, Accu: 100.00%\n",
            "Train Epoch: 2 [170/194 (87%)]\tLoss: 0.030611, Accu: 100.00%\n",
            "Train Epoch: 2 [180/194 (92%)]\tLoss: 0.075167, Accu: 100.00%\n",
            "Train Epoch: 2 [190/194 (97%)]\tLoss: 0.035160, Accu: 100.00%\n",
            "[5.326016664505005s]\tTrain Epoch 2 is done.\n",
            "Fri Aug 14 05:33:56 2020\n",
            "\n",
            "Test set (65 samples): Average loss: 0.2602, Accuracy: 93.85%\n",
            "\n",
            "Epoch 2 model saved!\n",
            "\n",
            "Fri Aug 14 05:34:27 2020\n",
            "Train Epoch: 3 [10/194 (5%)]\tLoss: 0.083160, Accu: 100.00%\n",
            "Train Epoch: 3 [20/194 (10%)]\tLoss: 0.019397, Accu: 100.00%\n",
            "Train Epoch: 3 [30/194 (15%)]\tLoss: 0.002878, Accu: 100.00%\n",
            "Train Epoch: 3 [40/194 (21%)]\tLoss: 0.016238, Accu: 100.00%\n",
            "Train Epoch: 3 [50/194 (26%)]\tLoss: 0.014659, Accu: 100.00%\n",
            "Train Epoch: 3 [60/194 (31%)]\tLoss: 0.037607, Accu: 100.00%\n",
            "Train Epoch: 3 [70/194 (36%)]\tLoss: 0.039181, Accu: 100.00%\n",
            "Train Epoch: 3 [80/194 (41%)]\tLoss: 0.038222, Accu: 100.00%\n",
            "Train Epoch: 3 [90/194 (46%)]\tLoss: 0.022223, Accu: 100.00%\n",
            "Train Epoch: 3 [100/194 (51%)]\tLoss: 0.375987, Accu: 80.00%\n",
            "Train Epoch: 3 [110/194 (56%)]\tLoss: 0.175928, Accu: 100.00%\n",
            "Train Epoch: 3 [120/194 (62%)]\tLoss: 0.057332, Accu: 100.00%\n",
            "Train Epoch: 3 [130/194 (67%)]\tLoss: 0.172351, Accu: 100.00%\n",
            "Train Epoch: 3 [140/194 (72%)]\tLoss: 0.024625, Accu: 100.00%\n",
            "Train Epoch: 3 [150/194 (77%)]\tLoss: 0.049444, Accu: 100.00%\n",
            "Train Epoch: 3 [160/194 (82%)]\tLoss: 0.018719, Accu: 100.00%\n",
            "Train Epoch: 3 [170/194 (87%)]\tLoss: 0.011112, Accu: 100.00%\n",
            "Train Epoch: 3 [180/194 (92%)]\tLoss: 0.022203, Accu: 100.00%\n",
            "Train Epoch: 3 [190/194 (97%)]\tLoss: 0.006762, Accu: 100.00%\n",
            "[5.7825610637664795s]\tTrain Epoch 3 is done.\n",
            "Fri Aug 14 05:34:33 2020\n",
            "\n",
            "Test set (65 samples): Average loss: 0.1900, Accuracy: 92.31%\n",
            "\n",
            "Epoch 3 model saved!\n",
            "\n",
            "Fri Aug 14 05:34:45 2020\n",
            "Train Epoch: 4 [10/194 (5%)]\tLoss: 0.047884, Accu: 100.00%\n",
            "Train Epoch: 4 [20/194 (10%)]\tLoss: 0.005101, Accu: 100.00%\n",
            "Train Epoch: 4 [30/194 (15%)]\tLoss: 0.009652, Accu: 100.00%\n",
            "Train Epoch: 4 [40/194 (21%)]\tLoss: 0.004937, Accu: 100.00%\n",
            "Train Epoch: 4 [50/194 (26%)]\tLoss: 0.012258, Accu: 100.00%\n",
            "Train Epoch: 4 [60/194 (31%)]\tLoss: 0.009480, Accu: 100.00%\n",
            "Train Epoch: 4 [70/194 (36%)]\tLoss: 0.007435, Accu: 100.00%\n",
            "Train Epoch: 4 [80/194 (41%)]\tLoss: 0.084635, Accu: 100.00%\n",
            "Train Epoch: 4 [90/194 (46%)]\tLoss: 0.013379, Accu: 100.00%\n",
            "Train Epoch: 4 [100/194 (51%)]\tLoss: 0.001910, Accu: 100.00%\n",
            "Train Epoch: 4 [110/194 (56%)]\tLoss: 0.004995, Accu: 100.00%\n",
            "Train Epoch: 4 [120/194 (62%)]\tLoss: 0.009905, Accu: 100.00%\n",
            "Train Epoch: 4 [130/194 (67%)]\tLoss: 0.002432, Accu: 100.00%\n",
            "Train Epoch: 4 [140/194 (72%)]\tLoss: 0.005451, Accu: 100.00%\n",
            "Train Epoch: 4 [150/194 (77%)]\tLoss: 0.003575, Accu: 100.00%\n",
            "Train Epoch: 4 [160/194 (82%)]\tLoss: 0.004608, Accu: 100.00%\n",
            "Train Epoch: 4 [170/194 (87%)]\tLoss: 0.005184, Accu: 100.00%\n",
            "Train Epoch: 4 [180/194 (92%)]\tLoss: 0.005349, Accu: 100.00%\n",
            "Train Epoch: 4 [190/194 (97%)]\tLoss: 0.001213, Accu: 100.00%\n",
            "[9.062025785446167s]\tTrain Epoch 4 is done.\n",
            "Fri Aug 14 05:34:54 2020\n",
            "\n",
            "Test set (65 samples): Average loss: 0.1875, Accuracy: 93.85%\n",
            "\n",
            "Epoch 4 model saved!\n",
            "\n",
            "Fri Aug 14 05:35:07 2020\n",
            "Train Epoch: 5 [10/194 (5%)]\tLoss: 0.016124, Accu: 100.00%\n",
            "Train Epoch: 5 [20/194 (10%)]\tLoss: 0.002395, Accu: 100.00%\n",
            "Train Epoch: 5 [30/194 (15%)]\tLoss: 0.005093, Accu: 100.00%\n",
            "Train Epoch: 5 [40/194 (21%)]\tLoss: 0.001452, Accu: 100.00%\n",
            "Train Epoch: 5 [50/194 (26%)]\tLoss: 0.002827, Accu: 100.00%\n",
            "Train Epoch: 5 [60/194 (31%)]\tLoss: 0.002797, Accu: 100.00%\n",
            "Train Epoch: 5 [70/194 (36%)]\tLoss: 0.002127, Accu: 100.00%\n",
            "Train Epoch: 5 [80/194 (41%)]\tLoss: 0.002017, Accu: 100.00%\n",
            "Train Epoch: 5 [90/194 (46%)]\tLoss: 0.004964, Accu: 100.00%\n",
            "Train Epoch: 5 [100/194 (51%)]\tLoss: 0.001059, Accu: 100.00%\n",
            "Train Epoch: 5 [110/194 (56%)]\tLoss: 0.001479, Accu: 100.00%\n",
            "Train Epoch: 5 [120/194 (62%)]\tLoss: 0.006335, Accu: 100.00%\n",
            "Train Epoch: 5 [130/194 (67%)]\tLoss: 0.001276, Accu: 100.00%\n",
            "Train Epoch: 5 [140/194 (72%)]\tLoss: 0.000495, Accu: 100.00%\n",
            "Train Epoch: 5 [150/194 (77%)]\tLoss: 0.001650, Accu: 100.00%\n",
            "Train Epoch: 5 [160/194 (82%)]\tLoss: 0.000245, Accu: 100.00%\n",
            "Train Epoch: 5 [170/194 (87%)]\tLoss: 0.010687, Accu: 100.00%\n",
            "Train Epoch: 5 [180/194 (92%)]\tLoss: 0.007382, Accu: 100.00%\n",
            "Train Epoch: 5 [190/194 (97%)]\tLoss: 0.006910, Accu: 100.00%\n",
            "[5.676884174346924s]\tTrain Epoch 5 is done.\n",
            "Fri Aug 14 05:35:13 2020\n",
            "\n",
            "Test set (65 samples): Average loss: 0.1737, Accuracy: 95.38%\n",
            "\n",
            "Epoch 5 model saved!\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PwVpb0ebdHFf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "a3adf561-277a-4d6a-ad63-15c1574d30bf"
      },
      "source": [
        "draw(epoch_size, A, B, C, D)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4nz61Nm7m6e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# cnn3d = CNN3D(t_dim=28,\n",
        "#         img_x=256, \n",
        "#         img_y=342,\n",
        "#         drop_p=0,\n",
        "#         fc_hidden1=256,\n",
        "#         fc_hidden2=256,\n",
        "#         num_classes=10)\n",
        "# torch.save(cnn3d, 'drive/My Drive/mycode/cnn3d.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APim3Pxn83rB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !pip install tensorwatch\n",
        "# import tensorwatch as tw\n",
        "# import torchvision\n",
        "# import torch\n",
        "# alexnet_model = torchvision.models.alexnet().to(torch.device('cuda'))\n",
        "# tw.draw_model(alexnet_model, [1, 3, 224, 224])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Duf2WFWyZ44h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from torch.utils.tensorboard import SummaryWriter\n",
        "# writer = SummaryWriter()\n",
        "# writer.add_graph(cnn3d, input_to_model=torch.zeros([1, 1, 28, 256, 342]), verbose=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}